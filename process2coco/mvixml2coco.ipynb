{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** IMPORTANT *** \n",
    "This code was written for training purposes. The code is shared only for knowledge sharing purposes. The code should not be used in any production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom COCO data set for object segmentation using Pascal VOC format\n",
    "\n",
    "You can run this notebook to generate the coco json format for a dataset in Pascal VOC format. \n",
    "\n",
    "Then you can run the viwer.ipynb notebook to visualize the coco annotations. \n",
    "\n",
    "\n",
    "Further instruction on how to create your own datasets, read the [tutorial](https://www.dlology.com/blog/how-to-create-custom-coco-data-set-for-object-detection/).\n",
    "\n",
    "This code is based on the git repo https://github.com/Tony607/voc2coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "\n",
    "START_BOUNDING_BOX_ID = 1\n",
    "PRE_DEFINE_CATEGORIES = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(root, name):\n",
    "    vars = root.findall(name)\n",
    "    return vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_check(root, name, length):\n",
    "    vars = root.findall(name)\n",
    "    if len(vars) == 0:\n",
    "        raise ValueError(\"Can not find %s in %s.\" % (name, root.tag))\n",
    "    if length > 0 and len(vars) != length:\n",
    "        raise ValueError(\n",
    "            \"The size of %s is supposed to be %d, but is %d.\"\n",
    "            % (name, length, len(vars))\n",
    "        )\n",
    "    if length == 1:\n",
    "        vars = vars[0]\n",
    "    return vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_as_int(filename):\n",
    "    try:\n",
    "        filename = filename.replace(\"\\\\\", \"/\")\n",
    "        filename = os.path.splitext(os.path.basename(filename))[0]\n",
    "        return int(filename)\n",
    "    except:\n",
    "        raise ValueError(\"Filename %s is supposed to be an integer.\" % (filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(xml_files):\n",
    "    \"\"\"Generate category name to id mapping from a list of xml files.\n",
    "    \n",
    "    Arguments:\n",
    "        xml_files {list} -- A list of xml file paths.\n",
    "    \n",
    "    Returns:\n",
    "        dict -- category name to id mapping.\n",
    "    \"\"\"\n",
    "    classes_names = []\n",
    "    for xml_file in xml_files:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall(\"object\"):\n",
    "#             print(member)\n",
    "            classes_names.append(member[1].text)\n",
    "    classes_names = list(set(classes_names))\n",
    "    classes_names.sort()\n",
    "    return {name: i for i, name in enumerate(classes_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method gets the segmentation for polyons. It should not be used to return RLE values because the assumption is\n",
    "# the annotated data does not contain crowds instead contain individual elements.\n",
    "\n",
    "def get_segmentation(object):\n",
    "    segmentations = []\n",
    "    segement_polygons = object.findall('segment_polygons')\n",
    "    # print(len(segement_polygons))\n",
    "    if len(segement_polygons) > 0:\n",
    "        assert len(segement_polygons) == 1 # there should be only one segment_polygon\n",
    "        polygons = segement_polygons[0].findall('polygon')\n",
    "        for polygon in polygons:\n",
    "            x_y_points = []\n",
    "            points = polygon.findall('point')\n",
    "            for point in points:\n",
    "                # for v in point.findall('value'):\n",
    "                #     print(v.text)\n",
    "                itert = point.itertext()\n",
    "                x_y_points.append(int(next(itert)))\n",
    "                x_y_points.append(int(next(itert)))\n",
    "                # assert next(itert) == None\n",
    "\n",
    "            # seg = poly2mask(x_points, y_points, [265, 256])  # TODO what should the shape be. is it correct to get the mask?\n",
    "            # print(seg.shape)\n",
    "            segmentations.append(x_y_points)\n",
    "    # print(segmentations)\n",
    "    return segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly2mask(vertex_row_coords, vertex_col_coords, shape):\n",
    "    fill_row_coords, fill_col_coords = draw.polygon(vertex_row_coords, vertex_col_coords, shape)\n",
    "    mask = np.zeros(shape, dtype=np.bool)\n",
    "    mask[fill_row_coords, fill_col_coords] = True\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(xml_files, json_file):\n",
    "    json_dict = {\"images\": [], \"type\": \"instances\", \"annotations\": [], \"categories\": []}\n",
    "    image_id_counter = 0\n",
    "    if PRE_DEFINE_CATEGORIES is not None:\n",
    "        categories = PRE_DEFINE_CATEGORIES\n",
    "    else:\n",
    "        categories = get_categories(xml_files)\n",
    "    bnd_id = START_BOUNDING_BOX_ID\n",
    "    for xml_file in xml_files:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        # path = get(root, \"path\")\n",
    "        # if len(path) == 1:\n",
    "        #     filename = os.path.basename(path[0].text)\n",
    "        # elif len(path) == 0:\n",
    "        #     filename = get_and_check(root, \"filename\", 1).text\n",
    "        # else:\n",
    "        #     raise ValueError(\"%d paths found in %s\" % (len(path), xml_file))\n",
    "        # ## The filename must be a number\n",
    "        filename = xml_file.split('/')[-1].split('.')[0] + '.jpg'\n",
    "        # print(filename)\n",
    "        # print('image counter', image_id_counter)\n",
    "        image_id = image_id_counter  # get_filename_as_int(filename)\n",
    "\n",
    "        size = get_and_check(root, \"size\", 1)\n",
    "        width = int(get_and_check(size, \"width\", 1).text)\n",
    "        height = int(get_and_check(size, \"height\", 1).text)\n",
    "        image = {\n",
    "            \"file_name\": filename,\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "            \"id\": image_id,  # TODO This id is not universal.\n",
    "        }\n",
    "        json_dict[\"images\"].append(image)\n",
    "        # Currently we do not support segmentation.\n",
    "        #  segmented = get_and_check(root, 'segmented', 1).text\n",
    "        #  assert segmented == '0'\n",
    "        for obj in get(root, \"object\"):\n",
    "            category = get_and_check(obj, \"name\", 1).text\n",
    "            if category not in categories:\n",
    "                new_id = len(categories)\n",
    "                categories[category] = new_id\n",
    "            category_id = categories[category]\n",
    "            bndbox = get_and_check(obj, \"bndbox\", 1)\n",
    "            xmin = int(get_and_check(bndbox, \"xmin\", 1).text) - 1\n",
    "            ymin = int(get_and_check(bndbox, \"ymin\", 1).text) - 1\n",
    "            xmax = int(get_and_check(bndbox, \"xmax\", 1).text)\n",
    "            ymax = int(get_and_check(bndbox, \"ymax\", 1).text)\n",
    "            assert xmax > xmin\n",
    "            assert ymax > ymin\n",
    "            o_width = abs(xmax - xmin)\n",
    "            o_height = abs(ymax - ymin)\n",
    "            o_segmentation = get_segmentation(obj)\n",
    "            if len(o_segmentation) > 0:\n",
    "                ann = {\n",
    "                    \"area\": o_width * o_height,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"bbox\": [xmin, ymin, o_width, o_height],\n",
    "                    \"category_id\": category_id,\n",
    "                    \"id\": bnd_id,\n",
    "                    \"ignore\": 0,\n",
    "                    \"segmentation\": o_segmentation,\n",
    "                }\n",
    "            # else:\n",
    "            #     ann = {\n",
    "            #         \"area\": o_width * o_height,\n",
    "            #         \"iscrowd\": 0,\n",
    "            #         \"image_id\": image_id,\n",
    "            #         \"bbox\": [xmin, ymin, o_width, o_height],\n",
    "            #         \"category_id\": category_id,\n",
    "            #         \"id\": bnd_id,\n",
    "            #         \"ignore\": 0,\n",
    "            #         # \"segmentation\": o_segmentation,\n",
    "            #     }\n",
    "\n",
    "                json_dict[\"annotations\"].append(ann)\n",
    "                bnd_id = bnd_id + 1\n",
    "        image_id_counter = image_id_counter + 1\n",
    "\n",
    "    for cate, cid in categories.items():\n",
    "        cat = {\"supercategory\": \"none\", \"id\": cid, \"name\": cate}\n",
    "        json_dict[\"categories\"].append(cat)\n",
    "\n",
    "    os.makedirs(os.path.dirname(json_file), exist_ok=True)\n",
    "    json_fp = open(json_file, \"w\")\n",
    "    json_str = json.dumps(json_dict)\n",
    "    json_fp.write(json_str)\n",
    "    json_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of xml files: 2\n",
      "Success: ./test-data/coco/output.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#     import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description=\"Convert Pascal VOC annotation to COCO format.\"\n",
    "#     )\n",
    "#     parser.add_argument(\"xml_dir\", help=\"Directory path to xml files.\", type=str)\n",
    "#     parser.add_argument(\"json_file\", help=\"Output COCO format json file.\", type=str)\n",
    "#     args = parser.parse_args()\n",
    "#     print(args)\n",
    "\n",
    "xml_dir = \"./test-data/VOC/Annotations\"\n",
    "json_file = \"./test-data/coco/output.json\"\n",
    "\n",
    "xml_files = glob.glob(os.path.join(xml_dir, \"*.xml\"))\n",
    "\n",
    "# If you want to do train/test split, you can pass a subset of xml files to convert function.\n",
    "print(\"Number of xml files: {}\".format(len(xml_files)))\n",
    "\n",
    "convert(xml_files, json_file)\n",
    "print(\"Success: {}\".format(json_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
