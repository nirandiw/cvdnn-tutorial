{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** IMPORTANT *** \n",
    "This code was written for training purposes. The code is shared only for knowledge sharing purposes. The code should not be used in any production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create custom COCO data set for object segmentation\n",
    "\n",
    "You can run the `voc2coco.py` script to generate a COCO data formatted JSON file for you.\n",
    "```\n",
    "python voc2coco.py ./test-data/VOC/Annotations ./test-data/coco/output.json\n",
    "```\n",
    "Then you can run the following Jupyter notebook to visualize the coco annotations. `COCO_Image_Viewer.ipynb`\n",
    "\n",
    "\n",
    "Further instruction on how to create your own datasets, read the [tutorial](https://www.dlology.com/blog/how-to-create-custom-coco-data-set-for-object-detection/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "\n",
    "START_BOUNDING_BOX_ID = 1\n",
    "PRE_DEFINE_CATEGORIES = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(root, name):\n",
    "    vars = root.findall(name)\n",
    "    return vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_check(root, name, length):\n",
    "    vars = root.findall(name)\n",
    "    if len(vars) == 0:\n",
    "        raise ValueError(\"Can not find %s in %s.\" % (name, root.tag))\n",
    "    if length > 0 and len(vars) != length:\n",
    "        raise ValueError(\n",
    "            \"The size of %s is supposed to be %d, but is %d.\"\n",
    "            % (name, length, len(vars))\n",
    "        )\n",
    "    if length == 1:\n",
    "        vars = vars[0]\n",
    "    return vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_as_int(filename):\n",
    "    try:\n",
    "        filename = filename.replace(\"\\\\\", \"/\")\n",
    "        filename = os.path.splitext(os.path.basename(filename))[0]\n",
    "        return int(filename)\n",
    "    except:\n",
    "        raise ValueError(\"Filename %s is supposed to be an integer.\" % (filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(xml_files):\n",
    "    \"\"\"Generate category name to id mapping from a list of xml files.\n",
    "    \n",
    "    Arguments:\n",
    "        xml_files {list} -- A list of xml file paths.\n",
    "    \n",
    "    Returns:\n",
    "        dict -- category name to id mapping.\n",
    "    \"\"\"\n",
    "    classes_names = []\n",
    "    for xml_file in xml_files:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall(\"object\"):\n",
    "#             print(member)\n",
    "            classes_names.append(member[1].text)\n",
    "    classes_names = list(set(classes_names))\n",
    "    classes_names.sort()\n",
    "    return {name: i for i, name in enumerate(classes_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method gets the segmentation for polyons. It should not be used to return RLE values because the assumption is\n",
    "# the annotated data does not contain crowds instead contain individual elements.\n",
    "\n",
    "def get_segmentation(object):\n",
    "    segmentations = []\n",
    "    segement_polygons = object.findall('segment_polygons')\n",
    "    # print(len(segement_polygons))\n",
    "    if len(segement_polygons) > 0:\n",
    "        assert len(segement_polygons) == 1 # there should be only one segment_polygon\n",
    "        polygons = segement_polygons[0].findall('polygon')\n",
    "        for polygon in polygons:\n",
    "            x_y_points = []\n",
    "            points = polygon.findall('point')\n",
    "            for point in points:\n",
    "                # for v in point.findall('value'):\n",
    "                #     print(v.text)\n",
    "                itert = point.itertext()\n",
    "                x_y_points.append(int(next(itert)))\n",
    "                x_y_points.append(int(next(itert)))\n",
    "                # assert next(itert) == None\n",
    "\n",
    "            # seg = poly2mask(x_points, y_points, [265, 256])  # TODO what should the shape be. is it correct to get the mask?\n",
    "            # print(seg.shape)\n",
    "            segmentations.append(x_y_points)\n",
    "    # print(segmentations)\n",
    "    return segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly2mask(vertex_row_coords, vertex_col_coords, shape):\n",
    "    fill_row_coords, fill_col_coords = draw.polygon(vertex_row_coords, vertex_col_coords, shape)\n",
    "    mask = np.zeros(shape, dtype=np.bool)\n",
    "    mask[fill_row_coords, fill_col_coords] = True\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(xml_files, json_file):\n",
    "    json_dict = {\"images\": [], \"type\": \"instances\", \"annotations\": [], \"categories\": []}\n",
    "    image_id_counter = 0\n",
    "    if PRE_DEFINE_CATEGORIES is not None:\n",
    "        categories = PRE_DEFINE_CATEGORIES\n",
    "    else:\n",
    "        categories = get_categories(xml_files)\n",
    "    bnd_id = START_BOUNDING_BOX_ID\n",
    "    for xml_file in xml_files:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        # path = get(root, \"path\")\n",
    "        # if len(path) == 1:\n",
    "        #     filename = os.path.basename(path[0].text)\n",
    "        # elif len(path) == 0:\n",
    "        #     filename = get_and_check(root, \"filename\", 1).text\n",
    "        # else:\n",
    "        #     raise ValueError(\"%d paths found in %s\" % (len(path), xml_file))\n",
    "        # ## The filename must be a number\n",
    "        filename = xml_file.split('/')[-1].split('.')[0] + '.jpg'\n",
    "        # print(filename)\n",
    "        # print('image counter', image_id_counter)\n",
    "        image_id = image_id_counter  # get_filename_as_int(filename)\n",
    "\n",
    "        size = get_and_check(root, \"size\", 1)\n",
    "        width = int(get_and_check(size, \"width\", 1).text)\n",
    "        height = int(get_and_check(size, \"height\", 1).text)\n",
    "        image = {\n",
    "            \"file_name\": filename,\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "            \"id\": image_id,  # TODO This id is not universal.\n",
    "        }\n",
    "        json_dict[\"images\"].append(image)\n",
    "        # Currently we do not support segmentation.\n",
    "        #  segmented = get_and_check(root, 'segmented', 1).text\n",
    "        #  assert segmented == '0'\n",
    "        for obj in get(root, \"object\"):\n",
    "            category = get_and_check(obj, \"name\", 1).text\n",
    "            if category not in categories:\n",
    "                new_id = len(categories)\n",
    "                categories[category] = new_id\n",
    "            category_id = categories[category]\n",
    "            bndbox = get_and_check(obj, \"bndbox\", 1)\n",
    "            xmin = int(get_and_check(bndbox, \"xmin\", 1).text) - 1\n",
    "            ymin = int(get_and_check(bndbox, \"ymin\", 1).text) - 1\n",
    "            xmax = int(get_and_check(bndbox, \"xmax\", 1).text)\n",
    "            ymax = int(get_and_check(bndbox, \"ymax\", 1).text)\n",
    "            assert xmax > xmin\n",
    "            assert ymax > ymin\n",
    "            o_width = abs(xmax - xmin)\n",
    "            o_height = abs(ymax - ymin)\n",
    "            o_segmentation = get_segmentation(obj)\n",
    "            if len(o_segmentation) > 0:\n",
    "                ann = {\n",
    "                    \"area\": o_width * o_height,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"bbox\": [xmin, ymin, o_width, o_height],\n",
    "                    \"category_id\": category_id,\n",
    "                    \"id\": bnd_id,\n",
    "                    \"ignore\": 0,\n",
    "                    \"segmentation\": o_segmentation,\n",
    "                }\n",
    "            # else:\n",
    "            #     ann = {\n",
    "            #         \"area\": o_width * o_height,\n",
    "            #         \"iscrowd\": 0,\n",
    "            #         \"image_id\": image_id,\n",
    "            #         \"bbox\": [xmin, ymin, o_width, o_height],\n",
    "            #         \"category_id\": category_id,\n",
    "            #         \"id\": bnd_id,\n",
    "            #         \"ignore\": 0,\n",
    "            #         # \"segmentation\": o_segmentation,\n",
    "            #     }\n",
    "\n",
    "                json_dict[\"annotations\"].append(ann)\n",
    "                bnd_id = bnd_id + 1\n",
    "        image_id_counter = image_id_counter + 1\n",
    "\n",
    "    for cate, cid in categories.items():\n",
    "        cat = {\"supercategory\": \"none\", \"id\": cid, \"name\": cate}\n",
    "        json_dict[\"categories\"].append(cat)\n",
    "\n",
    "    os.makedirs(os.path.dirname(json_file), exist_ok=True)\n",
    "    json_fp = open(json_file, \"w\")\n",
    "    json_str = json.dumps(json_dict)\n",
    "    json_fp.write(json_str)\n",
    "    json_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of xml files: 2\n",
      "Success: ./test-data/coco/output.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#     import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description=\"Convert Pascal VOC annotation to COCO format.\"\n",
    "#     )\n",
    "#     parser.add_argument(\"xml_dir\", help=\"Directory path to xml files.\", type=str)\n",
    "#     parser.add_argument(\"json_file\", help=\"Output COCO format json file.\", type=str)\n",
    "#     args = parser.parse_args()\n",
    "#     print(args)\n",
    "\n",
    "xml_dir = \"./test-data/VOC/Annotations\"\n",
    "json_file = \"./test-data/coco/output.json\"\n",
    "\n",
    "xml_files = glob.glob(os.path.join(xml_dir, \"*.xml\"))\n",
    "\n",
    "# If you want to do train/test split, you can pass a subset of xml files to convert function.\n",
    "print(\"Number of xml files: {}\".format(len(xml_files)))\n",
    "\n",
    "convert(xml_files, json_file)\n",
    "print(\"Success: {}\".format(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
